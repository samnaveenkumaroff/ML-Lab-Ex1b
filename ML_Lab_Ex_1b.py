# -*- coding: utf-8 -*-
"""ML Lab Ex 1b.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kXlK8gYb9tmXFguMXlX9FopG8-uNBs8u
"""

# AIM
# To prepare the data suitable for the machine learning model, perform data cleaning, data
# reduction and data transformation on the given dataset using python implementation.

# DESCRIPTION
# Data preprocessing is a process of preparing the raw data and making it suitable for a machine
# learning model.
#  Data cleaning can be applied to “clean” the data by filling in missing values,
#  smoothing noisy data, identifying or removing outliers, and resolving inconsistencies.
#  Data reduction can reduce data size by, for instance, aggregating, eliminating
#  redundant features, or clustering.
#  Data transformations (e.g., normalization) may be applied, where data are scaled to
#  fall within a smaller range like 0.0 to 1.0.

# DATA CLEANING
# Data cleaning is the process of removing incorrect, corrupted, garbage, incorrectly formatted,
# duplicate, or incomplete data within a dataset. Having wrong or bad quality data can be
# detrimental to processes and analysis.
#  Check for Missing Values
# o Data imputation - attribute with 10% missing
# o Replace NaN with a Scalar Value (mean, median, mode, random, KNN etc.)
#  Check for Duplicates
#  Detect Outliers

# DATA REDUCTION:
# Data reduction techniques can be applied to obtain a reduced representation of the data set
# that is much smaller in volume, yet closely maintains the integrity of the original data.
#  Dimensionality reduction, numerosity reduction, data compression.
#  Feature selection and Feature extraction
#  Drop missing values
#  Drop the outliers
#  Drop duplicates

# DATA TRANSFORMATION:
# Data transformation is a technique used to convert the raw data into a suitable format.

#  Normalization - Data normalization involves converting all data variable into a given
# range.
# o Min-max - This method implements a linear transformation on the original
# Data
# o Z-score – This method normalizes the value using the mean and standard
# deviation
#  Encoding method - convert the categorical features into its numeric representation.
# o Label encoding - each label is assigned a unique integer based on alphabetical
# o ordering between 0 and n_classes-1 where n is the number of distinct labels.
# o One-Hot encoding - creates additional features based on the number of unique
# o values in the categorical feature, create dummy variables.

# 1. Calculate the % of missing values in a column (URK22AI1043)
import pandas as pd

# Load the dataset
df = pd.read_csv('insurance.csv')

def calculate_missing_percentage(df, column_name):
    missing_percentage = df[column_name].isnull().mean() * 100
    return missing_percentage

# Example usage
print(calculate_missing_percentage(df, 'bmi'))

# 2. Replace missing value with mean if the % of missing value is less than 10% (URK22AI1043)
def replace_missing_with_mean(df, column_name):
    missing_percentage = df[column_name].isnull().mean() * 100
    if missing_percentage < 10:
        df[column_name].fillna(df[column_name].mean(), inplace=True)
    return df

# Example usage
df = replace_missing_with_mean(df, 'bmi')
print(df['bmi'])

# 3. Perform the mode imputation for a categorical data (URK22AI1043)
def mode_imputation(df, column_name):
    mode_value = df[column_name].mode()[0]
    df[column_name].fillna(mode_value, inplace=True)
    return df

# Example usage
df = mode_imputation(df, 'region')
print(df['region'])

# 4. Perform a KNN Imputer to estimate the missing values (URK22AI1043)
from sklearn.impute import KNNImputer

def knn_imputer(df, n_neighbors=5):
    imputer = KNNImputer(n_neighbors=n_neighbors)
    df_imputed = pd.DataFrame(imputer.fit_transform(df.select_dtypes(include=[float, int])), columns=df.select_dtypes(include=[float, int]).columns)
    df[df_imputed.columns] = df_imputed
    return df

# Example usage
df = knn_imputer(df)
print(df)

# 5. Drop the columns with more than 10% missing values and display the size (URK22AI1043)
def drop_columns_with_missing_values(df, threshold=10):
    threshold_percentage = threshold / 100
    df_dropped = df.loc[:, df.isnull().mean() <= threshold_percentage]
    return df_dropped

# Example usage
df_dropped = drop_columns_with_missing_values(df)
print(df_dropped.shape)
print(df_dropped)

# 6. Drop the rows with outlier Z-score value > 3 and display the size (URK22AI1043)
from scipy.stats import zscore

def drop_outliers(df):
    z_scores = zscore(df.select_dtypes(include=[float, int]))
    abs_z_scores = abs(z_scores)
    filtered_entries = (abs_z_scores < 3).all(axis=1)
    df_outliers_removed = df[filtered_entries]
    return df_outliers_removed

# Example usage
df_outliers_removed = drop_outliers(df)
print(df_outliers_removed.shape)
print(df_outliers_removed)

# 7. Drop the duplicate rows based on more than 50% of columns having the same value (URK22AI1043)
def drop_custom_duplicates(df, threshold=0.5):
    num_columns = df.shape[1]
    threshold_count = int(threshold * num_columns)

    mask = df.apply(lambda row: (row == row.mode()[0]).sum() > threshold_count, axis=1)

    df_dropped_duplicates = df[~mask]
    return df_dropped_duplicates

# Example usage
df_dropped_duplicates = drop_custom_duplicates(df)
print(df_dropped_duplicates.shape)
print(df_dropped_duplicates)

# 8. Rescale your data using min-max normalization for a numerical feature (URK22AI1043)
from sklearn.preprocessing import MinMaxScaler

def min_max_normalization(df, column_name):
    scaler = MinMaxScaler()
    df[[column_name]] = scaler.fit_transform(df[[column_name]])
    return df

# Example usage
df = min_max_normalization(df, 'bmi')
print(df['bmi'])

# 9. Binarize the data by using binarizer class in Python (URK22AI1043)
from sklearn.preprocessing import Binarizer

def binarize_data(df, column_name, threshold=0.5):
    binarizer = Binarizer(threshold=threshold)
    df[[column_name]] = binarizer.fit_transform(df[[column_name]])
    return df

# Example usage
df = binarize_data(df, 'bmi', threshold=30)
print(df['bmi'])

# 10. Perform the one-hot encoding for a categorical feature (URK22AI1043)
def one_hot_encoding(df, column_name):
    df_encoded = pd.get_dummies(df, columns=[column_name])
    return df_encoded

# Example usage
df = one_hot_encoding(df, 'region')
print(df)

#Crafted With Love By Sam Naveenkumar .V